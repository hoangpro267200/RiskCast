# app.py ‚Äî RISKCAST v4.7 (fixed ptp & robust) ‚Äî patched by Kai
# -------------------------------------------------------------------
# M·ª•c ƒë√≠ch:
#   - ·ª®ng d·ª•ng Streamlit ƒë·ªÉ minh ho·∫° v√† ch·∫°y m√¥ h√¨nh ra quy·∫øt ƒë·ªãnh mua
#     b·∫£o hi·ªÉm v·∫≠n t·∫£i qu·ªëc t·∫ø d·ª±a tr√™n: Fuzzy AHP, TOPSIS, Monte Carlo,
#     VaR & CVaR, v√† (t√πy ch·ªçn) ARIMA cho d·ª± b√°o chu·ªói th·ªùi gian.
#   - Phi√™n b·∫£n n√†y t·ªëi ∆∞u ·ªïn ƒë·ªãnh, x·ª≠ l√Ω edge-case (scalar arrays),
#     export Excel/PDF an to√†n, v√† ch·ª©a comment ti·∫øng Vi·ªát ph·ª•c v·ª• NCKH.
#
# H∆∞·ªõng d·∫´n ng·∫Øn:
#   - C√†i dependencies trong requirements.txt (streamlit, numpy, pandas,
#     plotly, statsmodels, openpyxl, fpdf, Pillow n·∫øu mu·ªën xu·∫•t ·∫£nh).
#   - Ch·∫°y: streamlit run app.py
#   - Trang b√™n tr√°i l√† input (gi√° tr·ªã l√¥ h√†ng, tuy·∫øn, ph∆∞∆°ng th·ª©c, v.v.)
#   - Nh·∫•n "PH√ÇN T√çCH & G·ª¢I √ù" ƒë·ªÉ ch·∫°y m√¥ ph·ªèng & nh·∫≠n k·∫øt qu·∫£.
#
# Ghi ch√∫ NCKH (t√†i li·ªáu k√®m):
#   - √ù t∆∞·ªüng: k·∫øt h·ª£p y·∫øu t·ªë ƒë·ªãnh t√≠nh (Fuzzy AHP) -> tr·ªçng s·ªë ti√™u ch√≠,
#     v√† ph∆∞∆°ng ph√°p nhi·ªÅu ti√™u ch√≠ (TOPSIS) -> x·∫øp h·∫°ng nh√† b·∫£o hi·ªÉm.
#   - ƒê·ªô b·∫•t ƒë·ªãnh (TFN) cho ph√©p m√¥ ph·ªèng ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn c·ªßa tr·ªçng s·ªë.
#   - C6 (R·ªßi ro kh√≠ h·∫≠u) m√¥ ph·ªèng b·∫±ng Monte Carlo d·ª±a tr√™n h·ªá s·ªë nh·∫°y
#     c·∫£m (sensitivity) theo t·ª´ng nh√† b·∫£o hi·ªÉm v√† tuy·∫øn h√†ng.
#   - VaR/CVaR t√≠nh tr√™n t·ªïn th·∫•t k·ª≥ v·ªçng = loss_rate * cargo_value.
#
# T·ªï ch·ª©c code:
#   - Ph·∫ßn ƒë·∫ßu: import + config giao di·ªán
#   - Helpers: auto_balance, defuzzify_centroid, try_plotly_to_png
#   - D·ªØ li·ªáu m·∫´u (load_sample_data)
#   - GUI (sidebar + tr·ªçng s·ªë)
#   - M√¥ ph·ªèng Monte Carlo (vectorized, cached)
#   - H√†m TOPSIS, VaR/CVaR, Forecast
#   - Ph√¢n t√≠ch & xu·∫•t k·∫øt qu·∫£
# -------------------------------------------------------------------

import io
import math
import uuid
import numpy as np
import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from fpdf import FPDF
import warnings
warnings.filterwarnings("ignore")

# Optional ARIMA (n·∫øu c√†i statsmodels)
try:
    from statsmodels.tsa.arima.model import ARIMA
    ARIMA_AVAILABLE = True
except Exception:
    ARIMA_AVAILABLE = False

# Optional image libs (Pillow) ‚Äî d√πng ƒë·ªÉ x·ª≠ l√Ω ·∫£nh tr∆∞·ªõc khi ch√®n v√†o PDF
HAS_PIL = False
try:
    from PIL import Image
    HAS_PIL = True
except Exception:
    HAS_PIL = False

# Page config + CSS (giao di·ªán "Green ESG")
st.set_page_config(page_title="RISKCAST v4.7 ‚Äî Green ESG", layout="wide", page_icon="üõ°Ô∏è")
st.markdown("""
<style>
  .stApp { background: linear-gradient(180deg,#0b3d0b 0%, #05320a 100%); color: #e9fbf0; font-family: 'Segoe UI', sans-serif; }
  h1 { color:#a3ff96; text-align:center; font-weight:800; }
  .card { background: rgba(255,255,255,0.03); padding:1rem; border-radius:10px; border:1px solid rgba(163,255,150,0.08); }
  .muted { color: #bfe8c6; font-size:0.95rem; }
  .small { font-size:0.85rem; color:#bfe8c6; }
  .result-box { background:#0f3d1f; padding:1rem; border-left:6px solid #3ef08a; border-radius:8px; }
</style>
""", unsafe_allow_html=True)

st.title("üõ°Ô∏è RISKCAST v4.7 ‚Äî Green ESG Insurance Advisor")
st.caption("ARIMA + MonteCarlo + VaR/CVaR + Fuzzy AHP + TOPSIS ‚Äî Stable build")

# -----------------------------
# Sidebar inputs (UI ch√≠nh)
# -----------------------------
with st.sidebar:
    st.header("Th√¥ng tin l√¥ h√†ng")
    cargo_value = st.number_input("Gi√° tr·ªã l√¥ h√†ng (USD)", min_value=1000, value=39000, step=1000)
    good_type = st.selectbox("Lo·∫°i h√†ng", ["ƒêi·ªán t·ª≠", "ƒê√¥ng l·∫°nh", "H√†ng kh√¥", "H√†ng nguy hi·ªÉm", "Kh√°c"])
    route = st.selectbox("Tuy·∫øn", ["VN - EU", "VN - US", "VN - Singapore", "VN - China", "Domestic"])
    method = st.selectbox("Ph∆∞∆°ng th·ª©c", ["Sea", "Air", "Truck"])
    month = st.selectbox("Th√°ng (1-12)", list(range(1,13)), index=8)
    priority = st.selectbox("∆Øu ti√™n", ["An to√†n t·ªëi ƒëa", "C√¢n b·∫±ng", "T·ªëi ∆∞u chi ph√≠"])

    st.markdown("---")
    st.header("M√¥ h√¨nh")
    use_fuzzy = st.checkbox("B·∫≠t Fuzzy AHP (TFN)", True)
    use_arima = st.checkbox("D√πng ARIMA ƒë·ªÉ d·ª± b√°o (n·∫øu c√≥)", True)
    use_var = st.checkbox("T√≠nh VaR & CVaR", True)
    use_mc = st.checkbox("Ch·∫°y Monte Carlo cho C6", True)
    mc_runs = st.number_input("S·ªë v√≤ng Monte Carlo", min_value=500, max_value=10000, value=2000, step=500)

# -----------------------------
# Helpers (H√†m ti·ªán √≠ch)
# -----------------------------
def auto_balance(weights, locked_flags):
    """
    C√¢n b·∫±ng t·ª± ƒë·ªông tr·ªçng s·ªë khi m·ªôt s·ªë ti√™u ch√≠ b·ªã lock.
    - weights: array-like (ti·ªÅn ch·ªânh)
    - locked_flags: boolean list (True n·∫øu ƒë√£ lock)
    Tr·∫£ v·ªÅ m·∫£ng tr·ªçng s·ªë chu·∫©n ho√° (t·ªïng = 1).
    """
    w = np.array(weights, dtype=float)
    locked = np.array(locked_flags, dtype=bool)
    locked_sum = w[locked].sum()
    free_idx = np.where(~locked)[0]
    # N·∫øu kh√¥ng c√≤n ti√™u ch√≠ t·ª± do
    if len(free_idx) == 0:
        if w.sum() == 0:
            w = np.ones_like(w) / len(w)
        else:
            w = w / w.sum()
        return np.round(w, 6)
    remaining = max(0.0, 1.0 - locked_sum)
    free_vals = w[free_idx]
    if free_vals.sum() == 0:
        w[free_idx] = remaining / len(free_idx)
    else:
        w[free_idx] = free_vals / free_vals.sum() * remaining
    w = np.clip(w, 0.0, 1.0)
    diff = 1.0 - w.sum()
    if abs(diff) > 1e-8:
        idx = free_idx[0] if len(free_idx)>0 else 0
        w[idx] += diff
    return np.round(w, 6)

def defuzzify_centroid(low, mid, high):
    """
    Defuzzification theo centroid ƒë∆°n gi·∫£n cho TFN.
    low, mid, high c√≥ th·ªÉ l√† m·∫£ng.
    """
    return (low + mid + high) / 3.0

def try_plotly_to_png(fig):
    """
    Th·ª≠ nhi·ªÅu c√°ch xu·∫•t plotly figure sang bytes PNG.
    Tr·∫£ v·ªÅ bytes ho·∫∑c None n·∫øu th·∫•t b·∫°i.
    """
    # C√°ch 1: fig.to_image() (kaleido)
    try:
        return fig.to_image(format="png")
    except Exception:
        pass
    # C√°ch 2: write_image -> save t·∫°m -> read
    try:
        import tempfile, os
        tmp = tempfile.NamedTemporaryFile(suffix=".png", delete=False)
        path = tmp.name
        fig.write_image(path)
        tmp.close()
        with open(path, "rb") as f:
            data = f.read()
        os.remove(path)
        return data
    except Exception:
        return None

# -----------------------------
# D·ªØ li·ªáu m·∫´u cho demo / NCKH
# -----------------------------
@st.cache_data
def load_sample_data():
    """
    T·∫°o d·ªØ li·ªáu l·ªãch s·ª≠ m·∫´u cho t·ª´ng tuy·∫øn (th√¥ng s·ªë r·ªßi ro c∆° b·∫£n theo th√°ng)
    v√† m·ªôt b·ªô m·∫´u t·ªïn th·∫•t (loss_rate) ƒë·ªÉ t√≠nh VaR.
    Trong nghi√™n c·ª©u th·ª±c t·∫ø, thay th·∫ø b·∫±ng d·ªØ li·ªáu l·ªãch s·ª≠.
    """
    months = list(range(1,13))
    base = {
        "VN - EU": [0.20,0.22,0.25,0.28,0.32,0.36,0.42,0.48,0.60,0.68,0.58,0.45],
        "VN - US": [0.30,0.33,0.36,0.40,0.45,0.50,0.56,0.62,0.75,0.72,0.60,0.52],
        "VN - Singapore": [0.15,0.16,0.18,0.20,0.22,0.26,0.30,0.32,0.35,0.34,0.28,0.25],
        "Domestic": [0.10,0.10,0.10,0.12,0.12,0.14,0.16,0.18,0.20,0.18,0.14,0.12],
        "VN - China": [0.18,0.19,0.21,0.24,0.26,0.30,0.34,0.36,0.40,0.38,0.32,0.28],
    }
    hist = pd.DataFrame({"month": months})
    for k,v in base.items():
        hist[k] = v
    rng = np.random.default_rng(123)
    losses = np.clip(rng.normal(loc=0.08, scale=0.02, size=2000), 0, 0.5)
    claims = pd.DataFrame({"loss_rate": losses})
    return hist, claims

historical, claims = load_sample_data()

# -----------------------------
# Ti√™u ch√≠, tr·ªçng s·ªë kh·ªüi t·∫°o
# -----------------------------
criteria = ["C1: T·ª∑ l·ªá ph√≠", "C2: Th·ªùi gian x·ª≠ l√Ω", "C3: T·ª∑ l·ªá t·ªïn th·∫•t",
            "C4: H·ªó tr·ª£ ICC", "C5: ChƒÉm s√≥c KH", "C6: R·ªßi ro kh√≠ h·∫≠u"]

# Kh·ªüi t·∫°o session_state ƒë·ªÉ gi·ªØ tr·∫°ng th√°i tr·ªçng s·ªë gi·ªØa c√°c l·∫ßn t∆∞∆°ng t√°c
if "weights" not in st.session_state:
    st.session_state["weights"] = np.array([0.20,0.15,0.20,0.20,0.10,0.15], dtype=float)
if "locked" not in st.session_state:
    st.session_state["locked"] = [False]*6

# -----------------------------
# UI: ph√¢n b·ªï tr·ªçng s·ªë (lock + auto-balance)
# -----------------------------
st.subheader("‚öñÔ∏è Ph√¢n b·ªï tr·ªçng s·ªë ti√™u ch√≠ (Lock & Auto-balance)")
cols = st.columns(6)
new_w = st.session_state["weights"].copy()
for i,c in enumerate(criteria):
    with cols[i]:
        st.markdown(f"**{c}**")
        # checkbox lock: l∆∞u v√†o session_state kh√≥a ri√™ng cho m·ªói ti√™u ch√≠
        st.checkbox("üîí Lock", value=st.session_state["locked"][i], key=f"lock_{i}", on_change=None)
        val = st.number_input("T·ªâ l·ªá", min_value=0.0, max_value=1.0, value=float(new_w[i]), step=0.01, key=f"w_in_{i}")
        new_w[i] = val
# c·∫≠p nh·∫≠t flags locked
for i in range(6):
    st.session_state["locked"][i] = st.session_state.get(f"lock_{i}", False)

# N√∫t reset tr·ªçng s·ªë m·∫∑c ƒë·ªãnh
if st.button("üîÑ Reset tr·ªçng s·ªë m·∫∑c ƒë·ªãnh"):
    st.session_state["weights"] = np.array([0.20,0.15,0.20,0.20,0.10,0.15], dtype=float)
    st.session_state["locked"] = [False]*6
else:
    st.session_state["weights"] = auto_balance(new_w, st.session_state["locked"])

weights_series = pd.Series(st.session_state["weights"], index=criteria)
fig_weights = px.pie(values=weights_series.values, names=weights_series.index, title="Ph√¢n b·ªï tr·ªçng s·ªë (Realtime)")
st.plotly_chart(fig_weights, use_container_width=True)

# -----------------------------
# D·ªØ li·ªáu m·∫´u c√°c c√¥ng ty b·∫£o hi·ªÉm
# -----------------------------
df = pd.DataFrame({
    "Company": ["Chubb","PVI","InternationalIns","BaoViet","Aon"],
    "C1: T·ª∑ l·ªá ph√≠": [0.30,0.28,0.26,0.32,0.24],
    "C2: Th·ªùi gian x·ª≠ l√Ω": [6,5,8,7,4],
    "C3: T·ª∑ l·ªá t·ªïn th·∫•t": [0.08,0.06,0.09,0.10,0.07],
    "C4: H·ªó tr·ª£ ICC": [9,8,6,9,7],
    "C5: ChƒÉm s√≥c KH": [9,8,5,7,6],
}).set_index("Company")

# sensitivity: h·ªá s·ªë nh·∫°y c·∫£m v·ªõi r·ªßi ro kh√≠ h·∫≠u (c√°c gi√° tr·ªã m·∫´u)
sensitivity = {"Chubb":0.95,"PVI":1.10,"InternationalIns":1.20,"BaoViet":1.05,"Aon":0.90}

route_key = route
# l·∫•y gi√° tr·ªã c∆° b·∫£n r·ªßi ro theo th√°ng / tuy·∫øn (t·ª´ d·ªØ li·ªáu m·∫´u)
base_climate = float(historical.loc[historical['month']==month, route_key].iloc[0]) if month in historical['month'].values else 0.40

df_adj = df.copy().astype(float)

# -----------------------------
# Monte Carlo vectorized cho C6 (hi·ªáu nƒÉng t·ªët)
# -----------------------------
@st.cache_data
def monte_carlo_climate(base_climate, sensitivity_map, mc_runs, rng_seed=2025):
    """
    Monte Carlo vectorized:
      - base_climate: gi√° tr·ªã r·ªßi ro c∆° b·∫£n c·ªßa tuy·∫øn (0-1)
      - sensitivity_map: dict{company: multiplier}
      - mc_runs: s·ªë v√≤ng m√¥ ph·ªèng
    Tr·∫£ v·ªÅ: names, means, stds (m·∫£ng t∆∞∆°ng ·ª©ng)
    """
    rng = np.random.default_rng(rng_seed)
    names = list(sensitivity_map.keys())
    n = len(names)
    mu = np.array([base_climate * sensitivity_map.get(name,1.0) for name in names], dtype=float)
    sigma = np.maximum(0.03, mu * 0.12)
    sims = rng.normal(loc=mu, scale=sigma, size=(int(mc_runs), n))
    sims = np.clip(sims, 0.0, 1.0)
    means = sims.mean(axis=0)
    stds = sims.std(axis=0)
    return names, means, stds

if use_mc:
    names_mc, mc_mean, mc_std = monte_carlo_climate(base_climate, sensitivity, mc_runs)
    # ƒë·∫£m b·∫£o th·ª© t·ª± kh·ªõp v·ªõi df_adj.index
    order = [names_mc.index(nm) for nm in df_adj.index]
    mc_mean = mc_mean[order]
    mc_std = mc_std[order]
else:
    mc_mean = np.zeros(len(df_adj), dtype=float)
    mc_std = np.zeros(len(df_adj), dtype=float)

# g√°n C6 (r·ªßi ro kh√≠ h·∫≠u) v√†o b·∫£ng d·ªØ li·ªáu
df_adj["C6: R·ªßi ro kh√≠ h·∫≠u"] = mc_mean

# ƒêi·ªÅu ch·ªânh: n·∫øu cargo_value qu√° l·ªõn, t·ª∑ l·ªá ph√≠ c√≥ th·ªÉ tƒÉng (v√≠ d·ª•)
if cargo_value > 50000:
    df_adj["C1: T·ª∑ l·ªá ph√≠"] *= 1.1

# -----------------------------
# H√†m TOPSIS (chu·∫©n)
# -----------------------------
def topsis(df_input, weight_series, cost_flags):
    """
    TOPSIS chu·∫©n:
      - df_input: DataFrame c√≥ c√°c c·ªôt t∆∞∆°ng ·ª©ng v·ªõi weight_series.index
      - weight_series: Series v·ªõi index = ti√™u ch√≠, gi√° tr·ªã = tr·ªçng s·ªë (t·ªïng=1)
      - cost_flags: dict ti√™u ch√≠ -> "cost" ho·∫∑c "benefit"
    Tr·∫£ v·ªÅ m·∫£ng score (0..1), c√†ng l·ªõn c√†ng t·ªët.
    """
    M = df_input[list(weight_series.index)].values.astype(float)
    denom = np.sqrt((M**2).sum(axis=0))
    denom[denom==0] = 1.0
    R = M / denom
    w = np.array(weight_series.values, dtype=float)
    V = R * w
    is_cost = np.array([cost_flags[c]=="cost" for c in weight_series.index])
    ideal_best = np.where(is_cost, V.min(axis=0), V.max(axis=0))
    ideal_worst = np.where(is_cost, V.max(axis=0), V.min(axis=0))
    d_plus = np.sqrt(((V - ideal_best)**2).sum(axis=1))
    d_minus = np.sqrt(((V - ideal_worst)**2).sum(axis=1))
    score = d_minus / (d_plus + d_minus + 1e-12)
    return score

# ƒê√°nh d·∫•u ti√™u ch√≠ l√† cost/benefit (m·ªôt s·ªë gi·∫£ ƒë·ªãnh minh ho·∫°)
cost_flags = {c: "cost" if c in ["C1: T·ª∑ l·ªá ph√≠", "C6: R·ªßi ro kh√≠ h·∫≠u"] else "benefit" for c in criteria}

# -----------------------------
# VaR / CVaR (ƒë∆°n gi·∫£n)
# -----------------------------
def compute_var_cvar(loss_rates, cargo_value, alpha=0.95):
    """
    T√≠nh VaR & CVaR ƒë∆°n gi·∫£n:
      - loss_rates: m·∫£ng t·ª∑ l·ªá t·ªïn th·∫•t (0..1)
      - cargo_value: gi√° tr·ªã h√†ng
      - alpha: confidence level (v√≠ d·ª• 0.95)
    Tr·∫£ v·ªÅ (VaR, CVaR) t√≠nh theo USD; None n·∫øu kh√¥ng c√≥ d·ªØ li·ªáu.
    """
    eps = 1e-9
    losses = np.array(loss_rates, dtype=float) * float(cargo_value)
    if losses.size == 0:
        return None, None
    var = np.percentile(losses, alpha*100)
    # tail: ph·∫ßn v∆∞·ª£t ho·∫∑c b·∫±ng VaR
    tail = losses[losses >= var - eps]
    cvar = float(tail.mean()) if len(tail)>0 else float(var)
    return float(var), float(cvar)

# -----------------------------
# Forecast route (ARIMA fallback)
# -----------------------------
def forecast_route(route_key, months_ahead=3):
    """
    D·ª± b√°o r·ªßi ro theo tuy·∫øn:
      - N·∫øu ARIMA c√≥ s·∫µn, c·ªë g·∫Øng fit ARIMA(1,1,1)
      - N·∫øu th·∫•t b·∫°i, fallback b·∫±ng trend tuy·∫øn t√≠nh ƒë∆°n gi·∫£n
    """
    series = historical[route_key].values if route_key in historical.columns else historical.iloc[:,1].values
    if use_arima and ARIMA_AVAILABLE:
        try:
            model = ARIMA(series, order=(1,1,1)).fit()
            fc = model.forecast(months_ahead)
            return np.asarray(series), np.asarray(fc)
        except Exception:
            pass
    last = np.array(series)
    avg = np.mean(last[-6:]) if len(last)>=6 else np.mean(last)
    trend = (last[-1] - last[-6]) / 6.0 if len(last)>=6 else 0.0
    fc = np.array([max(0, last[-1] + (i+1)*trend) for i in range(months_ahead)])
    return last, fc

# -----------------------------
# N√∫t ch·∫°y ch√≠nh: Ph√¢n t√≠ch & G·ª£i √Ω
# -----------------------------
if st.button("üöÄ PH√ÇN T√çCH & G·ª¢I √ù"):
    with st.spinner("ƒêang ch·∫°y m√¥ ph·ªèng v√† t·ªëi ∆∞u..."):
        # weights hi·ªán th·ªùi (Series) ‚Äî c√≥ th·ªÉ b·ªã defuzzify n·∫øu d√πng fuzzy
        weights = weights_series.copy()
        if use_fuzzy:
            # "B·∫•t ƒë·ªãnh TFN (%)": m·ª©c bi·∫øn ƒë·ªông cho TFN (v√≠ d·ª• 15%)
            f = float(st.sidebar.slider("B·∫•t ƒë·ªãnh TFN (%)", 0, 50, 15))
            low = np.maximum(weights*(1 - f/100.0), 1e-9)
            high = np.minimum(weights*(1 + f/100.0), 0.9999)
            defuz = defuzzify_centroid(low, weights.values, high)
            weights = pd.Series(defuz/defuz.sum(), index=weights.index)

        # TOPSIS: t√≠nh score cho t·ª´ng c√¥ng ty
        scores = topsis(df_adj, weights, cost_flags)
        results = pd.DataFrame({
            "company": df_adj.index,
            "score": scores,
            "C6_mean": mc_mean,
            "C6_std": mc_std
        }).sort_values("score", ascending=False).reset_index(drop=True)
        results["rank"] = results.index + 1
        results["recommend_icc"] = results["score"].apply(lambda x: "ICC A" if x>=0.75 else ("ICC B" if x>=0.5 else "ICC C"))

        # -----------------------------
        # Confidence calc (robust)
        # Ghi ch√∫ NCKH: confidence = h√†m k·∫øt h·ª£p gi·ªØa ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa C6 v√† ƒë·ªô bi·∫øn ƒë·ªông gi·ªØa c√°c ti√™u ch√≠
        # -----------------------------
        eps = 1e-9
        cv_c6 = np.where(results["C6_mean"].values == 0, 0.0,
                         results["C6_std"].values / (results["C6_mean"].values + eps))
        conf_c6 = 1.0 / (1.0 + cv_c6)

        # ƒë·∫£m b·∫£o numpy array, x·ª≠ l√Ω tr∆∞·ªùng h·ª£p scalar
        conf_c6 = np.asarray(conf_c6)
        if conf_c6.ndim == 0:
            conf_c6 = np.full(len(results), float(conf_c6))

        if np.ptp(conf_c6) > 0:
            conf_c6_scaled = 0.3 + 0.7 * (conf_c6 - conf_c6.min()) / (np.ptp(conf_c6) + 1e-12)
        else:
            conf_c6_scaled = np.full_like(conf_c6, 0.65, dtype=float)

        # ƒë·ªô bi·∫øn ƒë·ªông gi·ªØa c√°c ti√™u ch√≠ (critic variability)
        crit_cv = df_adj.std(axis=1).values / (df_adj.mean(axis=1).values + eps)
        conf_crit = 1.0 / (1.0 + crit_cv)

        # ensure array
        conf_crit = np.asarray(conf_crit)
        if conf_crit.ndim == 0:
            conf_crit = np.full(len(results), float(conf_crit))

        if np.ptp(conf_crit) > 0:
            conf_crit_scaled = 0.3 + 0.7 * (conf_crit - conf_crit.min()) / (np.ptp(conf_crit) + 1e-12)
        else:
            conf_crit_scaled = np.full_like(conf_crit, 0.65, dtype=float)

        # confidence cu·ªëi c√πng: geometric mean gi·ªØa 2 y·∫øu t·ªë (t∆∞∆°ng ƒë·ªëi)
        conf_final = np.sqrt(conf_c6_scaled * conf_crit_scaled)
        order_map = {comp: float(conf_final[i]) for i, comp in enumerate(df_adj.index)}
        results["confidence"] = results["company"].map(order_map).round(3)

        # -----------------------------
        # VaR & CVaR (n·∫øu b·∫≠t)
        # -----------------------------
        var95, cvar95 = (None, None)
        if use_var:
            var95, cvar95 = compute_var_cvar(results["C6_mean"].values, cargo_value, alpha=0.95)

        # -----------------------------
        # Forecast cho tuy·∫øn + v·∫Ω bi·ªÉu ƒë·ªì
        # -----------------------------
        hist_series, fc = forecast_route(route)
        months_hist = list(range(1, len(hist_series)+1))
        months_fc = list(range(len(hist_series)+1, len(hist_series)+1+len(fc)))
        fig_forecast = go.Figure()
        fig_forecast.add_trace(go.Scatter(x=months_hist, y=hist_series, mode='lines+markers', name='L·ªãch s·ª≠'))
        fig_forecast.add_trace(go.Scatter(x=months_fc, y=fc, mode='lines+markers', name='D·ª± b√°o', line=dict(color='lime')))
        fig_forecast.update_layout(title=f"D·ª± b√°o r·ªßi ro: {route}", xaxis_title="Th√°ng index", yaxis_title="R·ªßi ro (0-1)")

        fig_topsis = px.bar(results.sort_values("score"), x="score", y="company", orientation='h', title="TOPSIS score (higher better)",
                            labels={"score":"Score","company":"C√¥ng ty"})

        st.success("Ho√†n t·∫•t ph√¢n t√≠ch")
        left, right = st.columns((2,1))
        with left:
            st.subheader("K·∫øt qu·∫£ x·∫øp h·∫°ng")
            st.table(results[["rank","company","score","confidence","recommend_icc"]].set_index("rank").round(3))
            st.markdown("<div class='result-box'><strong>ƒê·ªÄ XU·∫§T:</strong> {} ‚Äî Score: {:.3f} ‚Äî Confidence: {:.2f}</div>".format(
                results.iloc[0]["company"], results.iloc[0]["score"], results.iloc[0]["confidence"]
            ), unsafe_allow_html=True)
        with right:
            st.subheader("T·ªïng quan")
            st.metric("VaR 95%", f"${var95:,.0f}" if var95 is not None else "N/A")
            st.metric("CVaR 95%", f"${cvar95:,.0f}" if cvar95 is not None else "N/A")
            st.plotly_chart(fig_weights, use_container_width=True)

        st.plotly_chart(fig_topsis, use_container_width=True)
        st.plotly_chart(fig_forecast, use_container_width=True)

        # -----------------------------
        # Export Excel (c·∫£i ti·∫øn)
        # -----------------------------
        excel_out = io.BytesIO()
        with pd.ExcelWriter(excel_out, engine="openpyxl") as writer:
            results.to_excel(writer, sheet_name="Result", index=False)
            df_adj.to_excel(writer, sheet_name="Adjusted_Data")
            pd.DataFrame({"weight": weights.values}, index=weights.index).to_excel(writer, sheet_name="Weights")
        excel_out.seek(0)
        st.download_button("‚¨áÔ∏è Xu·∫•t Excel (K·∫øt qu·∫£)", excel_out, file_name="riskcast_result.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

        # -----------------------------
        # Export PDF (3 trang) ‚Äî x·ª≠ l√Ω ·∫£nh an to√†n
        # -----------------------------
        pdf = FPDF(unit="mm", format="A4")
        pdf.set_auto_page_break(auto=True, margin=12)
        # Th·ª≠ th√™m font DejaVu n·∫øu c√≥ ttf trong repo, n·∫øu kh√¥ng fallback Arial
        try:
            pdf.add_font("DejaVu", "", fname="DejaVuSans.ttf", uni=True)
            pdf.set_font("DejaVu", size=12)
        except Exception:
            pdf.set_font("Arial", size=12)

        # Trang 1: Executive summary + b·∫£ng top 5
        pdf.add_page()
        pdf.set_font_size(16)
        pdf.cell(0, 8, "RISKCAST v4.7 ‚Äî Executive Summary", ln=1)
        pdf.ln(2)
        pdf.set_font_size(10)
        pdf.cell(0, 6, f"Route: {route}    Month: {month}    Method: {method}", ln=1)
        pdf.cell(0, 6, f"Cargo value: ${cargo_value:,}    Priority: {priority}", ln=1)
        pdf.ln(4)
        pdf.set_font_size(11)
        summary_text = f"Recommended insurer: {results.iloc[0]['company']} ({results.iloc[0]['recommend_icc']})\nTOPSIS Score: {results.iloc[0]['score']:.4f}\nConfidence: {results.iloc[0]['confidence']:.2f}"
        if var95 is not None:
            summary_text += f"\nVaR95: ${var95:,.0f} | CVaR95: ${cvar95:,.0f}"
        pdf.multi_cell(0, 6, summary_text, align="L")
        pdf.ln(6)
        pdf.set_font_size(10)
        # table header
        pdf.cell(20,6,"Rank",1); pdf.cell(60,6,"Company",1); pdf.cell(40,6,"Score",1); pdf.cell(35,6,"Confidence",1); pdf.ln()
        for idx, row in results.head(5).iterrows():
            pdf.cell(20,6,str(int(row["rank"])),1); pdf.cell(60,6,str(row["company"])[:30],1)
            pdf.cell(40,6,f"{row['score']:.4f}",1); pdf.cell(35,6,f"{row['confidence']:.2f}",1); pdf.ln()

        # Trang 2: bi·ªÉu ƒë·ªì TOPSIS
        pdf.add_page()
        pdf.set_font_size(14)
        pdf.cell(0,8,"TOPSIS Scores", ln=1)
        img_bytes = try_plotly_to_png(fig_topsis)
        if img_bytes and HAS_PIL:
            try:
                im = Image.open(io.BytesIO(img_bytes))
                tmp = f"tmp_{uuid.uuid4().hex}_topsis.png"
                im.save(tmp)
                pdf.image(tmp, x=15, w=180)
            except Exception:
                pdf.set_font_size(10)
                pdf.cell(0,6,"(Kh√¥ng th·ªÉ xu·∫•t bi·ªÉu ƒë·ªì TOPSIS ‚Äî PIL export failed)", ln=1)
        elif img_bytes:
            # n·∫øu kh√¥ng c√≥ PIL, th·ª≠ ghi tr·ª±c ti·∫øp file t·∫°m
            try:
                tmp = f"tmp_{uuid.uuid4().hex}_topsis.png"
                with open(tmp, "wb") as f:
                    f.write(img_bytes)
                pdf.image(tmp, x=15, w=180)
            except Exception:
                pdf.set_font_size(10)
                pdf.cell(0,6,"(Kh√¥ng th·ªÉ xu·∫•t bi·ªÉu ƒë·ªì TOPSIS ‚Äî image save failed)", ln=1)
        else:
            pdf.set_font_size(10)
            pdf.cell(0,6,"(Bi·ªÉu ƒë·ªì TOPSIS kh√¥ng th·ªÉ xu·∫•t sang ·∫£nh)", ln=1)
            pdf.ln(4)
            for idx,row in results.iterrows():
                pdf.cell(0,5,f"{int(row['rank'])}. {row['company']} ‚Äî Score: {row['score']:.4f} ‚Äî Conf: {row['confidence']:.2f}", ln=1)

        # Trang 3: Forecast & VaR
        pdf.add_page()
        pdf.set_font_size(14)
        pdf.cell(0,8,"Forecast (ARIMA or fallback) & VaR", ln=1)
        img_bytes2 = try_plotly_to_png(fig_forecast)
        if img_bytes2 and HAS_PIL:
            try:
                im2 = Image.open(io.BytesIO(img_bytes2))
                tmp2 = f"tmp_{uuid.uuid4().hex}_forecast.png"
                im2.save(tmp2)
                pdf.image(tmp2, x=10, w=190)
            except Exception:
                pdf.set_font_size(10)
                pdf.cell(0,6,"(Kh√¥ng th·ªÉ xu·∫•t bi·ªÉu ƒë·ªì Forecast ‚Äî PIL failed)", ln=1)
        elif img_bytes2:
            try:
                tmp2 = f"tmp_{uuid.uuid4().hex}_forecast.png"
                with open(tmp2, "wb") as f:
                    f.write(img_bytes2)
                pdf.image(tmp2, x=10, w=190)
            except Exception:
                pdf.set_font_size(10)
                pdf.cell(0,6,"(Kh√¥ng th·ªÉ xu·∫•t bi·ªÉu ƒë·ªì Forecast ‚Äî image save failed)", ln=1)
        else:
            pdf.set_font_size(10)
            pdf.cell(0,6,"(Bi·ªÉu ƒë·ªì Forecast kh√¥ng th·ªÉ xu·∫•t)", ln=1)
        pdf.ln(6)
        if var95 is not None:
            pdf.set_font_size(11)
            pdf.cell(0,6,f"VaR 95%: ${var95:,.0f}", ln=1)
            pdf.cell(0,6,f"CVaR 95%: ${cvar95:,.0f}", ln=1)

        # Output PDF bytes
        try:
            pdf_bytes = pdf.output(dest="S").encode("latin-1")
        except Exception:
            pdf_bytes = pdf.output(dest="S").encode("utf-8", errors="ignore")
        st.download_button("‚¨áÔ∏è Xu·∫•t PDF b√°o c√°o (3 trang)", data=pdf_bytes, file_name="RISKCAST_report.pdf", mime="application/pdf")

# Footer / credit
st.markdown("<br><div class='muted small'>RISKCAST v4.7 ‚Äî Green ESG theme. Author: B√πi Xu√¢n Ho√†ng.</div>", unsafe_allow_html=True)

# -------------------------------------------------------------------
# H∆∞·ªõng ph√°t tri·ªÉn / ki·ªÉm th·ª≠ (g·ª£i √Ω cho ph·∫ßn NCKH)
# -------------------------------------------------------------------
# 1) Nghi√™n c·ª©u th·ª±c nghi·ªám:
#    - Thay 'historical' b·∫±ng d·ªØ li·ªáu th·ª±c t·∫ø l·∫•y t·ª´ c·∫£ng, weather API, claim logs.
#    - So s√°nh k·∫øt qu·∫£ model (top insurer) v·ªõi l·ª±a ch·ªçn th·ª±c t·∫ø, t√≠nh m·ª©c ti·∫øt ki·ªám ph√≠.
# 2) Th·ª≠ nghi·ªám sensitivity:
#    - Thay ƒë·ªïi 'f' (TFN uncertainty) v√† xem ƒë·ªô ·ªïn ƒë·ªãnh ranking.
# 3) Validation VaR/CVaR:
#    - D√πng d·ªØ li·ªáu t·ªïn th·∫•t l·ªãch s·ª≠ ƒë·ªÉ backtest VaR/CVaR (hit rate).
# 4) T·ªëi ∆∞u:
#    - Th√™m calibration cho cost_flags (c√°c ti√™u ch√≠ cost/benefit n√™n d·ª±a tr√™n domain).
#    - N√¢ng c·∫•p forecast b·∫±ng SARIMA ho·∫∑c Prophet n·∫øu c·∫ßn.
# -------------------------------------------------------------------
